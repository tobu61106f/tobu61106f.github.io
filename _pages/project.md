---
layout: archive
title: "Project"
permalink: /project/
author_profile: true
redirect_from:
  - /research
---

# Scientific Machine Learning/Machine Learning for Science (AI4Science)
## Convex Importance-Weight Optimization for Diffusion Model Training Timesteps
**Convex Optimization Course Project, Author: *Ziqing Chang*, *Zhiyun Yu*
The Problem: 
Standard DDPM training uses "uniform" weights ğ‘¤_ğ‘¡=1\/ğ‘‡ or â€cosine" weights , which ignores that different timesteps ğ‘¡ have different loss magnitudes and variances.
Our Method: 
The Convex Formulation (P) We find the optimal weights ğ‘¤^âˆ— by solving a strictly convex quadratic program (QP): 
minâ”¬(ğ‘¤âˆˆÎ”^ğ‘‡ )â¡ â€ƒğ¹(ğ‘¤)=âŸ(âˆ‘_(ğ‘¡=1)^ğ‘‡â–’ã€–ğ‘¤_ğ‘¡ (ğ‘™_ğ‘¡ )Â Ì‚ ã€—)â”¬"Weighted Loss" +ğœ† âŸ(âˆ‘_(ğ‘¡=1)^ğ‘‡â–’ã€–ğ‘¤_ğ‘¡^2 ğœ_ğ‘¡^2 ã€—)â”¬"Weighted Variance" 
We tranning the Baseline Model to collect empirical data (ğ‘™_t )Â Ì‚ğ‘ğ‘›ğ‘‘ ğœ_ğ‘¡^2 on the MNIST Set, later we will use KKT conditions to find the closed-form solution on primal model for ğ‘¤^âˆ—



---
# IC Design

---

